length(novel.lines)
## so now we have the effecttive novel.lines , from this we want to create
## a string of text so we can use paste to glue all of the lines together
novel <- paste(novel.lines , collapse=" ")
length(novel)
novel
novel.lower <- tolower(novel)
class(novel.lower)
moby.words <- strsplit(novel.lower,"\\W")
class(moby.words)
length(moby.words)
length(moby.words[[1]])
moby.word.vector <- unlist(moby.words)
length(moby.word.vector)
moby.word.vector[1:20]
not.blanks <- which(moby.word.vector!="")
moby.word.vector <- moby.word.vector[not.blanks]
whales <- which(moby.word.vector=='whale')
whales.hits <- length(whales)
whale.hits/length(moby.word.vector)
whales <- which(moby.word.vector=='whale')
whale.hits <- length(whales)
whale.hits/length(moby.word.vector)
the <- which(moby.word.vector == "the")
the.hits <- length(the)
the.hits/length(moby.word.vector)
100*(the.hits/length(moby.word.vector))
100*(whale.hits/length(moby.word.vector))
length(unique(moby.word.vector))  ## thats big
plot(moby.freqs)
plot(moby.freqs)
moby.freqs <- table(moby.word.vector)
plot(moby.freqs)
sorted.moby.freqs <- sort(moby.freqs, decreasing=TRUE)
sorted.moby.freqs[1:10]
sorted.moby.rel.freqs <- 100*(sorted.moby.freqs/sum(sorted.moby.freqs))
sorted.moby.rel.freqs[1:10]
plot(sorted.moby.rel.freqs[1:10], type="p",xlab="Top Ten words In Moby Dick
by Rel Freq",ylab="Percentage of Full text")
plot(sorted.moby.rel.freqs[1:10], type="p",xlab="Top Ten words In Moby Dick
by Rel Freq",ylab="Percentage of Full text",xaxt="n")
plot(sorted.moby.rel.freqs[1:10], type="a",xlab="Top Ten words In Moby Dick
by Rel Freq",ylab="Percentage of Full text",xaxt="n")
plot(sorted.moby.rel.freqs[1:10], type="b",xlab="Top Ten words In Moby Dick
by Rel Freq",ylab="Percentage of Full text",xaxt="n")
plot(sorted.moby.rel.freqs[1:10], type="p",xlab="Top Ten words In Moby Dick
by Rel Freq",ylab="Percentage of Full text",xaxt="n")
axis(1,1:10,labels=names(sorted.moby.rel.freqs[1:10]))
plot(sorted.moby.rel.freqs[1:10], type="b",xlab="Top Ten words In Moby Dick
by Rel Freq",ylab="Percentage of Full text",xaxt="n")
axis(1,1:10,labels=names(sorted.moby.rel.freqs[1:10]))
pie(table(sorted.moby.rel.freqs[1:10]))
pie(moby.freqs)
pie(moby.freqs[1:10])
pie(sorted.moby.freqs[1:10])
pie(sorted.moby.freqs[1:10])
hist(sorted.moby.freqs[1:10])
bar(sorted.moby.freqs[1:10])
plot(sorted.moby.freqs[1:10])
boxplot(sorted.moby.freqs)
boxplot(sorted.moby.freqs[1:10])
boxplot(sorted.moby.rel.freqs)
boxplot(sorted.moby.rel.freqs[1:10])
library(readxl)
install.packages("readxl")
query <- "Healthy cat food"
library(tm)
my.docs <- VectorSource(c(doc.list, query))
my.docs$Names <- c(names(doc.list), "query")
doc1 <- "Stray cats are running all over the place. I see 10 a day!"
doc2 <- "Cats are killers. They kill billions of animals a year."
doc3 <- "The best food in Columbus, OH is   the North Market."
doc4 <- "Brand A is the best tasting cat food around. Your cat will love it."
doc5 <- "Buy Brand C cat food for your cat. Brand C makes healthy and happy cats."
doc6 <- "The Arnold Classic came to town this weekend. It reminds us to be healthy."
doc7 <- "I have nothing to say. In summary, I have told you nothing."
doc.list <- list(doc1, doc2, doc3, doc4, doc5, doc6, doc7)
N.docs <- length(doc.list)
names(doc.list) <- paste0("doc", c(1:N.docs))
query <- "Healthy cat food"
library(tm)
my.docs <- VectorSource(c(doc.list, query))
my.docs$Names <- c(names(doc.list), "query")
my.docs
?VectorSource
docs <- c("This is a text.","This is another one.")
vs <- VectorSource(docs)
vs
inspect(VCorpus(vs))
vs
vs$Names
vs
library(tm)
my.docs <- VectorSource(c(doc.list, query))
my.docs$Names <- c(names(doc.list), "query")
my.corpus <- Corpus(my.docs)
my.corpus
my.corpus <- tm_map(my.corpus, removePunctuation)
my.corpus$doc1
my.corpus
my.corpus$doc1
inspect(my.corpus)
my.corpus$doc1
a <- unlist(my.corpus)
a
length(a)
str(my.corpus)
my.corpus$doc1
my.corpus$doc 1
my.corpus$doc_1
my.docs
?Corpora
?Corpus
my.docs <- VectorSource(c(doc.list, query))
my.docs$Names <- c(names(doc.list), "query")
my.corpus <- Corpus(my.docs)
my.corpus
inspect(my.corpus)
my.docs
my.corpus[[1]]
doc1 <- "Stray cats are running all over the place. I see 10 a day!"
doc2 <- "Cats are killers. They kill billions of animals a year."
doc3 <- "The best food in Columbus, OH is   the North Market."
doc4 <- "Brand A is the best tasting cat food around. Your cat will love it."
doc5 <- "Buy Brand C cat food for your cat. Brand C makes healthy and happy cats."
doc6 <- "The Arnold Classic came to town this weekend. It reminds us to be healthy."
doc7 <- "I have nothing to say. In summary, I have told you nothing."
doc.list <- list(doc1, doc2, doc3, doc4, doc5, doc6, doc7)
N.docs <- length(doc.list)
names(doc.list) <- paste0("doc", c(1:N.docs))
query <- "Healthy cat food"
library(tm)
my.docs <- VectorSource(c(doc.list, query))
my.docs$Names <- c(names(doc.list), "query")
my.corpus <- Corpus(my.docs)
my.corpus
my.corpus <- tm_map(my.corpus, removePunctuation)
my.corpus$doc1
library(Snowball)
my.corpus <- tm_map(my.corpus, stemDocument)
my.corpus$doc1
rm(list = ls())
install.packages("Snowball")
install.packages("Snowball")
doc1 <- "Stray cats are running all over the place. I see 10 a day!"
doc2 <- "Cats are killers. They kill billions of animals a year."
doc3 <- "The best food in Columbus, OH is   the North Market."
doc4 <- "Brand A is the best tasting cat food around. Your cat will love it."
doc5 <- "Buy Brand C cat food for your cat. Brand C makes healthy and happy cats."
doc6 <- "The Arnold Classic came to town this weekend. It reminds us to be healthy."
doc7 <- "I have nothing to say. In summary, I have told you nothing."
doc.list <- list(doc1, doc2, doc3, doc4, doc5, doc6, doc7)
N.docs <- length(doc.list)
names(doc.list) <- paste0("doc", c(1:N.docs))
query <- "Healthy cat food"
library(tm)
my.docs <- VectorSource(c(doc.list, query))
my.docs$Names <- c(names(doc.list), "query")
my.corpus <- Corpus(my.docs)
my.corpus
my.corpus <- tm_map(my.corpus, removePunctuation)
my.corpus$doc1
library(SnowballC)
my.corpus <- tm_map(my.corpus, stemDocument)
my.corpus$doc1
my.corpus <- tm_map(my.corpus, removeNumbers)
my.corpus <- tm_map(my.corpus, tolower)
my.corpus <- tm_map(my.corpus, stripWhitespace)
my.corpus$doc1
term.doc.matrix.stm <- TermDocumentMatrix(my.corpus)
inspect(term.doc.matrix.stm[0:14, ])
term.doc.matrix.stm <- TermDocumentMatrix(my.corpus)
inspect(term.doc.matrix.stm[0:14, ])
rm(list-ls())
rm(list=ls())
doc1 <- "Stray cats are running all over the place. I see 10 a day!"
doc2 <- "Cats are killers. They kill billions of animals a year."
doc3 <- "The best food in Columbus, OH is   the North Market."
doc4 <- "Brand A is the best tasting cat food around. Your cat will love it."
doc5 <- "Buy Brand C cat food for your cat. Brand C makes healthy and happy cats."
doc6 <- "The Arnold Classic came to town this weekend. It reminds us to be healthy."
doc7 <- "I have nothing to say. In summary, I have told you nothing."
doc.list <- list(doc1, doc2, doc3, doc4, doc5, doc6, doc7)
N.docs <- length(doc.list)
names(doc.list) <- paste0("doc", c(1:N.docs))
query <- "Healthy cat food"
library(tm)
my.docs <- VectorSource(c(doc.list, query))
my.docs$Names <- c(names(doc.list), "query")
my.corpus <- Corpus(my.docs)
my.corpus
my.corpus <- tm_map(my.corpus, content_transformer(removePunctuation))
my.corpus$doc1
doc1 <- "Stray cats are running all over the place. I see 10 a day!"
doc2 <- "Cats are killers. They kill billions of animals a year."
doc3 <- "The best food in Columbus, OH is   the North Market."
doc4 <- "Brand A is the best tasting cat food around. Your cat will love it."
doc5 <- "Buy Brand C cat food for your cat. Brand C makes healthy and happy cats."
doc6 <- "The Arnold Classic came to town this weekend. It reminds us to be healthy."
doc7 <- "I have nothing to say. In summary, I have told you nothing."
doc.list <- list(doc1, doc2, doc3, doc4, doc5, doc6, doc7)
N.docs <- length(doc.list)
names(doc.list) <- paste0("doc", c(1:N.docs))
query <- "Healthy cat food"
library(tm)
my.docs <- VectorSource(c(doc.list, query))
my.docs$Names <- c(names(doc.list), "query")
my.corpus <- Corpus(my.docs)
my.corpus
my.corpus <- tm_map(my.corpus, content_transformer(removePunctuation))
my.corpus$doc1
library(SnowballC)
my.corpus <- tm_map(my.corpus, content_transformer(stemDocument))
my.corpus$doc1
my.corpus <- tm_map(my.corpus, content_transformer(removeNumbers))
my.corpus <- tm_map(my.corpus, content_transformer(tolower))
my.corpus <- tm_map(my.corpus, content_transformer(stripWhitespace))
my.corpus$doc1
term.doc.matrix.stm <- TermDocumentMatrix(my.corpus)
inspect(term.doc.matrix.stm[0:14, ])
term.doc.matrix <- as.matrix(term.doc.matrix.stm)
cat("Dense matrix representation costs", object.size(term.doc.matrix), "bytes.\n",
"Simple triplet matrix representation costs", object.size(term.doc.matrix.stm),
"bytes.")
get.tf.idf.weights <- function(tf.vec, df) {
# Computes tfidf weights from a term frequency vector and a document
# frequency scalar
weight = rep(0, length(tf.vec))
weight[tf.vec > 0] = (1 + log2(tf.vec[tf.vec > 0])) * log2(N.docs/df)
weight
}
cat("A word appearing in 4 of 6 documents, occuring 1, 2, 3, and 6 times, respectively: \n",
get.tf.idf.weights(c(1, 2, 3, 0, 0, 6), 4))
get.tf.idf.weights <- function(tf.vec, df) {
# Computes tfidf weights from a term frequency vector and a document
# frequency scalar
weight = rep(0, length(tf.vec))
weight[tf.vec > 0] = (1 + log2(tf.vec[tf.vec > 0])) * log2(N.docs/df)
weight
}
cat("A word appearing in 4 of 6 documents, occuring 1, 2, 3, and 6 times, respectively: \n",
get.tf.idf.weights(c(1, 2, 3, 0, 0, 6), 4))
get.weights.per.term.vec <- function(tfidf.row) {
term.df <- sum(tfidf.row[1:N.docs] > 0)
tf.idf.vec <- get.tf.idf.weights(tfidf.row, term.df)
return(tf.idf.vec)
}
tfidf.matrix <- t(apply(term.doc.matrix, c(1), FUN = get.weights.per.term.vec))
colnames(tfidf.matrix) <- colnames(term.doc.matrix)
tfidf.matrix[0:3, ]
angle <- seq(-pi, pi, by = pi/16)
plot(cos(angle) ~ angle, type = "b", xlab = "angle in radians", main = "Cosine similarity by angle")
plot of chunk unnamed-chunk-16
angle <- seq(-pi, pi, by = pi/16)
plot(cos(angle) ~ angle, type = "b", xlab = "angle in radians", main = "Cosine similarity by angle")
tfidf.matrix <- scale(tfidf.matrix, center = FALSE, scale = sqrt(colSums(tfidf.matrix^2)))
tfidf.matrix[0:3, ]
tfidf.matrix[0:3, ]
angle <- seq(-pi, pi, by = pi/16)
plot(cos(angle) ~ angle, type = "b", xlab = "angle in radians", main = "Cosine similarity by angle")
query.vector <- tfidf.matrix[, (N.docs + 1)]
tfidf.matrix <- tfidf.matrix[, 1:N.docs]
doc.scores <- t(query.vector) %*% tfidf.matrix
doc.scores <- t(query.vector) %*% tfidf.matrix
results.df <- data.frame(doc = names(doc.list), score = t(doc.scores), text = unlist(doc.list))
results.df <- results.df[order(results.df$score, decreasing = TRUE), ]
options(width = 2000)
print(results.df, row.names = FALSE, right = FALSE, digits = 2)
library(lattice)
#Build the horizontal and vertical axis information
hor <- c("214", "215", "216", "224", "211", "212", "213", "223", "226", "225")
ver <- paste("DM1-", hor, sep="")
#Build the fake correlation matrix
nrowcol <- length(ver)
cor <- matrix(runif(nrowcol*nrowcol, min=0.4), nrow=nrowcol, ncol=nrowcol, dimnames = list(hor, ver))
for (i in 1:nrowcol) cor[i,i] = 1
#Build the plot
rgb.palette <- colorRampPalette(c("blue", "yellow"), space = "rgb")
levelplot(cor, main="stage 12-14 array correlation matrix", xlab="", ylab="", col.regions=rgb.palette(120), cuts=100, at=seq(0,1,0.01))
rm(list = ls())
library(lda)
text <- scan("http://www.gutenberg.org/cache/epub/2701/pg2701.txt",what="character",sep = "\n")
class(text)
length(text)
# start and end of the novel
start <- which(text=="CHAPTER 1. Loomings.")
end <- which(text == "End of Project Gutenberg's Moby Dick; or The Whale, by Herman Melville")
## the effective novel length
novel.lines <- text[start:(end-1)]
length(novel.lines)
## so now we have the effecttive novel.lines , from this we want to create
## a string of text so we can use paste to glue all of the lines together
novel <- paste(novel.lines , collapse=" ")
length(novel)
## our use of the function paste above gives us a character vector with a
## single element that consists of the entire text.
## now next we have to convert entire text to lowercase letters, then break
## up the resulting character vectors so that each word is one in the
## final vector
novel.lower <- tolower(novel)
class(novel.lower)
moby.words <- strsplit(novel.lower,"\\W")
class(moby.words)
length(moby.words)
## we can access the items in a list using double brackets Here the
## entire vector of words that is in item 1 moby.words[[1]]
## and we can see how many items are in the vector in the first list
## item , like this
length(moby.words[[1]])
## well, in this case the list seems extraneous. In fact it is .We
## only have a list here because that is the way that strsplit output
## its  result. So lets get rid of it.
moby.word.vector <- unlist(moby.words)
length(moby.word.vector)
## now have a look at some of the words
moby.word.vector[1:20]
## when we use \\W , punctuation gets stripped and these remindered of
## where the punc characters were get left as residue.
## we can figure out the POSITIONS of these blanks by using which ,
## which(moby.word.vector == "")
## we can figure out the POSITIONS of these blanks using not equals
## operator !=
not.blanks <- which(moby.word.vector!="")
## so not.blanks is now a vector of the 'positions' of items in the
## moby.word.vector that are not blanks.
## so we can overwrite the existing moby.word.vector with a pared down
## version that omits the blanks , like this
moby.word.vector <- moby.word.vector[not.blanks]
## once you have all the words in a vector , you can do some cool
## searching :
whales <- which(moby.word.vector=='whale')
whale.hits <- length(whales)
whale.hits/length(moby.word.vector)
## compare to "the"
the <- which(moby.word.vector == "the")
the.hits <- length(the)
the.hits/length(moby.word.vector)
## we can make the percentages easier to read
100*(the.hits/length(moby.word.vector))
100*(whale.hits/length(moby.word.vector))
## we can figure out how many unique words there are in the novel
length(unique(moby.word.vector))  ## thats big
## we can create an entire frequency list of all the words
moby.freqs <- table(moby.word.vector)
sorted.moby.freqs <- sort(moby.freqs, decreasing=TRUE)
sorted.moby.freqs[1:10]
## now we can calculate the relative frequencies of all the words
sorted.moby.rel.freqs <- 100*(sorted.moby.freqs/sum(sorted.moby.freqs))
sorted.moby.rel.freqs[1:10]
## plot for the frequency of highest 10 frequencies
plot(sorted.moby.rel.freqs[1:10], type="b",xlab="Top Ten words In Moby Dick
by Rel Freq",ylab="Percentage of Full text",xaxt="n")
axis(1,1:10,labels=names(sorted.moby.rel.freqs[1:10]))
## we can create the pie(different types of graphs) chart for top frequency words
pie(sorted.moby.freqs[1:10])
# first of all remove every object in workspace
rm(list = ls())
library(lda)
text <- scan("/home/anupam/Calibre Library/Ritchie and Kernighan/ebook - The C Programming Language Ritchie & kernighan -.doc (4)
",what="character",sep="\n")
# first of all remove every object in workspace
rm(list = ls())
library(lda)
text <- scan("/home/anupam/Calibre Library/Ritchie and Kernighan/ebook - The C Programming Language Ritchie & kernighan -.doc (4)
ebook - The C Programming Language Ritchie - Ritchie and Kernighan.txt",what="character",sep="\n")
# first of all remove every object in workspace
rm(list = ls())
library(lda)
text <- scan("C.txt",what="character",sep="\n")
tex
text
length(text)
head(text)
text[1:19]
install.packages("choroplethr")
install.packages("acs")
install.packages("acs")
install.packages("choroplethr")
install.packages("rook")
install.packages("Rook")
library(Root)
#
# This application runs any file found in tempdir() through brew.
#
s <- Rhttpd$new()
## Not run:
s$start(quiet=TRUE)
## End(Not run)
cat("<h1>Random Number: <%=rnorm(1)%></h1>",
file=file.path(tempdir(),"index.html"))
s$add(name="random",
app=Builder$new(
Brewery$new(url="/",root=tempdir()),
Redirect$new("/index.html")
)
)
## Not run:
s$browse(
'
random
'
)
# Opens a browser window to the app.
## End(Not run)
library(Rook)
#
# This application runs any file found in tempdir() through brew.
#
s <- Rhttpd$new()
## Not run:
s$start(quiet=TRUE)
## End(Not run)
cat("<h1>Random Number: <%=rnorm(1)%></h1>",
file=file.path(tempdir(),"index.html"))
s$add(name="random",
app=Builder$new(
Brewery$new(url="/",root=tempdir()),
Redirect$new("/index.html")
)
)
## Not run:
s$browse(
'
random
'
)
# Opens a browser window to the app.
## End(Not run)
library(Rook)
#
# This application runs any file found in tempdir() through brew.
#
s <- Rhttpd$new()
## Not run:
s$start(quiet=TRUE)
## End(Not run)
cat("<h1>Random Number: <%=rnorm(1)%></h1>",
file=file.path(tempdir(),"index.html"))
s$add(name="random",
app=Builder$new(
Brewery$new(url="/",root=tempdir()),
Redirect$new("/index.html")
)
)
## Not run:
s$browse(
'
random
'
)
# Opens a browser window to the app.
## End(Not run)
file.remove(file.path(tempdir(),"index.html"))
s$remove(all=TRUE)
rm(s)
text <- scan("C.txt",what="character",sep="\n")
ls()
text
rm(list=ls())
install.package("Shiny")
install.packages("Shiny")
install.packages("shiny")
?shiny
library(shiny)
shiny::runApp('Text_Analysis')
shiny::runApp('Text_Analysis')
shiny::runApp('Text_Analysis')
shiny::runApp('Text_Analysis')
shiny::runApp('Text_Analysis')
shiny::runApp('census-app')
library(map)
library(map)
shiny::runApp('census-app')
shiny::runApp('stockVis')
shiny::runApp('Text_Analysis')
source('~/RProject/Text_Analysis/extractfile.R')
shiny::runApp('Text_Analysis')
shiny::runApp('Text_Analysis')
shiny::runApp('Text_Analysis')
shiny::runApp('Text_Analysis')
shiny::runApp('Text_Analysis')
shiny::runApp('Text_Analysis')
shiny::runApp('Text_Analysis')
shiny::runApp('Text_Analysis')
shiny::runApp('Text_Analysis')
shiny::runApp('Text_Analysis')
shiny::runApp('stockVis')
shiny::runApp('Text_Analysis')
shiny::runApp('Text_Analysis')
shiny::runApp('Text_Analysis')
shiny::runApp('Text_Analysis')
list.files()
getwd()
setwd("Text_Analysis")
list.files()
source("extracttext.R")
extractText("the the hello heh the theh our dkk ",2,6,"apply stoplist")
getwd()
source("extracttext.R")
extractText("the the hello heh the theh our dkk ",2,6,"apply stoplist")
source("extracttext.R")
extractText("the the hello heh the theh our dkk ",2,6,"apply stoplist")
source("extracttext.R")
extractText("the the hello heh the theh our dkk ",2,6,"apply stoplist")
source('~/RProject/Text_Analysis/extractfile.R')
source('~/RProject/Text_Analysis/extractfile.R')
source('~/RProject/Text_Analysis/extractfile.R')
source('~/RProject/Text_Analysis/extractfile.R')
shiny::runApp()
shiny::runApp()
source('~/RProject/Text_Analysis/extractfile.R')
shiny::runApp()
